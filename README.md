### Foundation of AI & Generative AI Course Exercises

This repository showcases the exercises and projects completed as part of the *Foundation of AI* course, where I explored the fundamental concepts of Generative AI, Deep Learning, and Foundation Models. The key learnings include:

- **Generative AI Fundamentals**: Understanding the core principles of generative models and their applications in various domains.
- **Deep Learning Fundamentals**: Gaining hands-on experience with neural networks, backpropagation, and optimization techniques.
- **Foundation Models & Adapting Them**: Exploring large-scale pre-trained models and techniques for fine-tuning and adapting them for specific tasks.

### Completed Exercises:
1. **Handwritten Digit Classification using MLP**: Built a Multi-Layer Perceptron (MLP) model to classify handwritten digits from the MNIST dataset.
2. **BERT Sentiment Classifier**: Implemented a BERT-based model for sentiment classification on text data.
3. **PyTorch & Hugging Face Scavenger Hunt**: Completed exercises involving PyTorch and Hugging Face for NLP tasks, including model implementation and dataset processing.
4. **Full Fine-tuning of BERT Model**: Performed full fine-tuning of a pre-trained BERT model for a specific downstream task.
5. **Transfer Learning with MobileNetV3**: Leveraged transfer learning techniques using MobileNetV3 to solve image classification tasks with limited labeled data.
